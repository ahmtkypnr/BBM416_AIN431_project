{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b625a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ahmtkypnr/BBM416_AIN431_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f72242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import Repository\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from torchvision.io import read_image\n",
    "from ultralytics import YOLO\n",
    "from torchvision.utils import draw_bounding_boxes, save_image\n",
    "import torch\n",
    "from BBM416_AIN431_project.data import create_shuffle_dataset, exclude_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1412d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_shuffle_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/content/dataset/classes.json') as f:\n",
    "  classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_exclude = []\n",
    "for class_, item in sorted(classes.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    print(class_, len(item))\n",
    "    if len(item) < 100:\n",
    "      classes_to_exclude.append(class_)\n",
    "exclude_classes(classes_to_exclude, \"/content/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adccb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = Repository(\"/content/dataset/images/esrgan_images\", clone_from=\"mfurkan03/Real_ESR-GAN_Standardized\",repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(\"/content/dataset/images/esrgan_images/1280\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(\"/content/dataset/images/esrgan_images/1280\", \"/content/dataset/images/1280\")\n",
    "os.rename(\"/content/dataset/images/test\", \"/content/dataset/images/test_640\")\n",
    "os.rename(\"/content/dataset/images/1280\",\"/content/dataset/images/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_xywh(xywh, W, H):\n",
    "    x,y,w_,h_ = xywh\n",
    "    x1 = (x - w_/2)*W; y1 = (y - h_/2)*H\n",
    "    x2 = (x + w_/2)*W; y2 = (y + h_/2)*H\n",
    "    return [int(x1), int(y1), int(x2), int(y2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt(path, W, H, class_names, valid_cls):\n",
    "    boxes, labels = [], []\n",
    "    if not os.path.exists(path):\n",
    "        return boxes, labels\n",
    "    for line in open(path):\n",
    "        cls, *xywh = line.strip().split()\n",
    "        cls = int(cls)\n",
    "        if cls not in valid_cls:\n",
    "            continue\n",
    "        box = denorm_xywh(list(map(float, xywh)), W, H)\n",
    "        boxes.append(box)\n",
    "        labels.append(class_names[cls])\n",
    "    return boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10dc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(res, class_names, valid_cls):\n",
    "    boxes, labels = [], []\n",
    "    for x1, y1, x2, y2, conf, cls in res:\n",
    "        cls = int(cls)\n",
    "        if cls not in valid_cls:\n",
    "            continue\n",
    "        boxes.append([int(x1),int(y1),int(x2),int(y2)])\n",
    "        labels.append(class_names[cls])\n",
    "    return boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(images_path, labels_path, model, img_extension=\".jpg\"):\n",
    "    # assume both models share the same names dict\n",
    "    class_names = model.model.names\n",
    "    valid_cls = set(class_names.keys())\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    gt_images_path = os.path.join(cwd, \"gt_images\")\n",
    "    pred_images_path = os.path.join(cwd, \"pred_images\")\n",
    "    os.mkdir(gt_images_path)\n",
    "    os.mkdir(pred_images_path)\n",
    "\n",
    "    for filename in os.listdir(images_path):\n",
    "        img_path = os.path.join(images_path, filename)\n",
    "        img_tensor = read_image(img_path)\n",
    "\n",
    "        boxes, labels = load_gt(os.path.join(labels_path, filename.replace(img_extension, \".txt\")), 1280, 1280, class_names, valid_cls)\n",
    "        if len(boxes) == 0:\n",
    "            continue\n",
    "        result_img = draw_bounding_boxes(img_tensor, boxes=torch.tensor(boxes), labels=labels, colors=\"blue\", width=3)\n",
    "        save_image(result_img.float()/255, os.path.join(gt_images_path, filename))\n",
    "\n",
    "        res = model(os.path.join(images_path, filename), imgsz=1280, verbose=False)[0].boxes.data.tolist()\n",
    "        boxes, labels = get_preds(res, class_names, valid_cls)\n",
    "        if len(boxes) == 0:\n",
    "            save_image(img_tensor.float()/255, os.path.join(pred_images_path, filename))\n",
    "            continue\n",
    "        result_img = draw_bounding_boxes(img_tensor, boxes=torch.tensor(boxes), labels=labels, colors=\"red\", width=3)\n",
    "        save_image(result_img.float()/255, os.path.join(pred_images_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/content/BBM416_AIN431_project/weights_fine_tuned/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f84180",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_output(\"/content/dataset/images/test\", \"/content/dataset/labels/test\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f54f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_directory(folder_path, zip_name):\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, start=folder_path)\n",
    "                zipf.write(file_path, arcname)\n",
    "\n",
    "# Usage\n",
    "zip_directory('/content/gt_images', 'gt_images.zip')\n",
    "\n",
    "zip_directory('/content/pred_images', 'pred_images.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
